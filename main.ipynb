{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data adopted from:\n",
    "\n",
    "## [FMA: A Dataset For Music Analysis](https://github.com/mdeff/fma)\n",
    "1. Go through the [paper] to understand what the data is about.\n",
    "2. Dataset downloaded from <https://github.com/mdeff/fma>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import utils\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where mp3 are stored.\n",
    "AUDIO_DIR = 'data/fma_files/'\n",
    "\n",
    "# Load metadata and features.\n",
    "_tracks = utils.load('data/fma_metadata/tracks.csv')\n",
    "_genres = utils.load('data/fma_metadata/genres.csv')\n",
    "_features = utils.load('data/fma_metadata/features.csv')\n",
    "_echonest = utils.load('data/fma_metadata/echonest.csv')\n",
    "\n",
    "np.testing.assert_array_equal(_features.index, _tracks.index)\n",
    "assert _echonest.index.isin(_tracks.index).all()\n",
    "\n",
    "_tracks.shape, _genres.shape, _features.shape, _echonest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inpect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = _tracks[_tracks['set', 'subset'] <= 'small']\n",
    "print('Shape of data: ',tracks.shape)\n",
    "print(tracks.iloc[2])\n",
    "# print(len(tracks.columns))\n",
    "# print(tracks.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "- Collect audio files into `data/audiofiles` directory\n",
    "- write metadata describing each audio file in `metadata.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioMetadata:\n",
    "    def __init__(self, file, title=None, artist=None, album=None):\n",
    "        self.file = file\n",
    "        self.title = title\n",
    "        self.artist=artist\n",
    "        self.album = album\n",
    "\n",
    "# Get track IDs\n",
    "track_ids = tracks.index.tolist()\n",
    "\n",
    "print('Tracks: ',len(track_ids))\n",
    "\n",
    "\n",
    "# Initialize list for metadata objects\n",
    "metadata = []\n",
    "\n",
    "# Generate filenames and other metadata for each track ID\n",
    "for track_id in track_ids:\n",
    "    # Assuming utils.get_audio_path() generates the filename\n",
    "    filepath_ = utils.get_audio_path(AUDIO_DIR, track_id)\n",
    "    file_ = str(track_id) + '.mp3'\n",
    "    title_=tracks.loc[track_id, ('track', 'title')]\n",
    "    artist_=tracks.loc[track_id, ('artist', 'name')]\n",
    "    album_ = tracks.loc[track_id, ('album', 'title')]\n",
    "    \n",
    "    # Create an instance of AudioMetadata with multiple parameters\n",
    "    metadata_object = AudioMetadata(file=file_,title=title_,artist=artist_,album=album_ )\n",
    "\n",
    "    # organize audio files in data/audiofiles\n",
    "    # destination_dir = 'data/audiofiles' # Destination directory\n",
    "    # os.makedirs(destination_dir, exist_ok=True) # Create the destination directory if it doesn't exist\n",
    "    # dest_file_path = os.path.join(destination_dir, filename_) # destination path\n",
    "    # shutil.copy(filepath_, dest_file_path) # copy\n",
    "    \n",
    "    # Add the object to the list\n",
    "    metadata.append(metadata_object)\n",
    "\n",
    "# Convert the list of objects to a list of dictionaries\n",
    "filenames_dict_list = [\n",
    "    {\n",
    "        'file': 'fma_dataset/'+obj.file,\n",
    "        'title':obj.title,\n",
    "        'description':'fma dataset',\n",
    "        'type':'MUSIC',\n",
    "        'artist':obj.artist,\n",
    "        'album':obj.album\n",
    "    }\n",
    "    for obj in metadata\n",
    "]\n",
    "\n",
    "# Save the list of dictionaries as a JSON file\n",
    "output_file = 'data/metadata.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(filenames_dict_list, json_file, indent=4, ensure_ascii=False)\n",
    "print('File written: ',output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select random 1000 from the dataset\n",
    "\n",
    "Filter the metadata for 1000 random objects, Write these in 1000metadata.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Step 1: Read the JSON file\n",
    "metadata8000 = 'data/metadata.json'  # Path to your input JSON file\n",
    "with open(metadata8000, 'r', encoding='utf-8') as json_file:\n",
    "    data = json.load(json_file)  # Load the JSON content into a Python object\n",
    "\n",
    "# Step 2: Select 1000 random objects\n",
    "num_objects_to_select = 1000\n",
    "if len(data) < num_objects_to_select:\n",
    "    print(f\"Warning: The file contains only {len(data)} objects. Adjusting to read all available.\")\n",
    "    num_objects_to_select = len(data)\n",
    "\n",
    "random_objects = random.sample(data, num_objects_to_select)  # Randomly select 1000 objects\n",
    "\n",
    "# Step 3: Write the selected objects to a new JSON file\n",
    "output_file = 'data/metadata1000.json'  # Path for the new JSON file\n",
    "with open(output_file, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(random_objects, json_file, indent=4, ensure_ascii=False)  # Write the data to the new file\n",
    "\n",
    "print(f\"Successfully wrote {len(random_objects)} random objects to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create simulation broadcasts  \n",
    "\n",
    "concatenate audio files by group to create 'broadcasts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "broadcastDIR='data/broadcasts'\n",
    "sourceDIR='data/audiofiles'\n",
    "\n",
    "if not os.path.exists(broadcastDIR):\n",
    "    os.makedirs(broadcastDIR)\n",
    "\n",
    "# Function to generate group name\n",
    "def get_group_name(counter):\n",
    "    # Calculate the first and second characters of the group name\n",
    "    first_char = chr((counter // 26) + ord('A'))\n",
    "    second_char = chr((counter % 26) + ord('A'))\n",
    "    return first_char + second_char\n",
    "\n",
    "# Function to concatenate audio files for a group\n",
    "def concatenate_audio_files(file_paths, output_name):\n",
    "    combined = AudioSegment.empty()\n",
    "    for file_path in file_paths:\n",
    "        audio = AudioSegment.from_file(file_path)\n",
    "        combined += audio\n",
    "    combined.export(output_name, format=\"mp3\")\n",
    "\n",
    "# Function to group and concatenate audio files\n",
    "def process_files(objects):\n",
    "    group_counter = 0\n",
    "    current_group = []\n",
    "\n",
    "    for i, obj in enumerate(objects):\n",
    "        current_group.append(obj)  # Add current object to group\n",
    "        \n",
    "        # If group has 5 elements or it's the last element\n",
    "        if len(current_group) == 5 or i == len(objects) - 1:\n",
    "            # Create group name\n",
    "            group_name = get_group_name(group_counter)\n",
    "            \n",
    "            # Collect file paths for concatenation\n",
    "            # file_paths = [os.path.join('audiofiles', obj['file']) for obj in current_group]\n",
    "            file_paths = [sourceDIR + '/' + os.path.basename(obj['file']) for obj in current_group]\n",
    "\n",
    "            output_file = f\"{broadcastDIR}/broadcast_{group_name}.mp3\"\n",
    "            \n",
    "            # Concatenate files for this group\n",
    "            concatenate_audio_files(file_paths, output_file)         \n",
    "            \n",
    "            # Move to the next group\n",
    "            group_counter += 1\n",
    "            current_group = []  # Reset group for the next batch\n",
    "\n",
    "# Step 1: Read the JSON file\n",
    "metadata1000 = 'data/metadata1000.json'  # Path to your input JSON file\n",
    "with open(metadata1000, 'r', encoding='utf-8') as json_file:\n",
    "    data = json.load(json_file)  # Load the JSON content into a Python object\n",
    "\n",
    "# Process files and group them\n",
    "process_files(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
